{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import numpy\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_fileName = []\n",
    "y_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for fileName in (glob.iglob('train/**/**', recursive=False)):\n",
    "    X_fileName.append(fileName)\n",
    "    y_val.append(fileName.split(\"\\\\\")[-2])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDf = pd.DataFrame()\n",
    "myDf['fileName'] = X_fileName\n",
    "myDf['label'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "myLabelEncoder = LabelEncoder()\n",
    "myDf['label_val'] = myLabelEncoder.fit_transform(myDf['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointremove(image):\n",
    "    \n",
    "    img=image.copy()\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(img, connectivity=4)\n",
    "    sizes = stats[:, -1]\n",
    "    for i in range(1, nb_components):\n",
    "        if sizes[i]<100 :\n",
    "            img[output==i]=0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxmeanpreprop(path):\n",
    "    img1 = cv2.imread(path)\n",
    "    g_img = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img = g_img.copy()\n",
    "    ret1,th1 = cv2.threshold(g_img,40,255,cv2.THRESH_BINARY)\n",
    "    th1=pointremove(th1)\n",
    "    blur = cv2.GaussianBlur(th1,(5,5),0)\n",
    "    ret2,th2 = cv2.threshold(blur,130,255,cv2.THRESH_OTSU)\n",
    "\n",
    "    a_img=th2&img\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(a_img, connectivity=4)\n",
    "    sizes = stats[:, -1]\n",
    "\n",
    "    max_label = 0\n",
    "    max_mean = 0\n",
    "\n",
    "    for i in range(1, nb_components):\n",
    "        mean=np.mean(a_img[output==i])\n",
    "        if mean > max_mean and sizes[i]>1000 :\n",
    "            max_label = i\n",
    "            max_mean = mean\n",
    "\n",
    "    img3 = np.zeros(output.shape)\n",
    "    img3[output == max_label] = 255\n",
    "    new_image = img3[stats[max_label][1]:stats[max_label][1]+stats[max_label][3],stats[max_label][0]:stats[max_label][0]+stats[max_label][2]]\n",
    "    image_for_input = cv2.resize(new_image, (100, 100), interpolation = cv2.INTER_NEAREST)\n",
    "    return image_for_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_generator(features, batch_size=16):\n",
    "    # Create empty arrays to contain batch of features and labels#\n",
    "    batch_features = np.zeros((batch_size, 100, 100, 1))\n",
    "    batch_labels = np.zeros((batch_size))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # choose random index in features\n",
    "            index = np.random.choice(len(features),1)\n",
    "            batch_features[i] = maxmeanpreprop(features.loc[index[0]]['fileName']).reshape([100, 100, 1])\n",
    "            batch_labels[i] = features.loc[index[0]]['label_val']\n",
    "        yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=200, epochs=5)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 338s 2s/step - loss: 19.8981 - accuracy: 0.4659\n",
      "Epoch 2/5\n",
      "153/200 [=====================>........] - ETA: 1:20 - loss: 1.1508 - accuracy: 0.6773"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "\n",
    "model.add(Conv2D(100, kernel_size=3, activation=\"relu\", input_shape=(100,100,1)))\n",
    "model.add(Conv2D(100, kernel_size=3, activation=\"relu\"))\n",
    "model.add(Conv2D(100, kernel_size=3, activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation=\"softmax\"))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# from keras.utils import to_categorical\n",
    "# y_binary = to_categorical(np.array(Y))\n",
    "# y_binary_test = to_categorical(np.array(Y_test))\n",
    "\n",
    "# print((np.expand_dims(np.array(X), axis=-1))\n",
    "\n",
    "# # Fit the model\n",
    "model.fit_generator(my_generator(myDf), samples_per_epoch=200, nb_epoch=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
