{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import numpy\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fileName = []\n",
    "y_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileName in sorted(glob.iglob('near-infrared/**/train_pose/**/**', recursive=False)):\n",
    "    X_fileName.append(fileName)\n",
    "    y_val.append(fileName.split(\"\\\\\")[-2])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDf = pd.DataFrame()\n",
    "myDf['fileName'] = X_fileName\n",
    "myDf['label'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "myLabelEncoder = LabelEncoder()\n",
    "myDf['label_val'] = myLabelEncoder.fit_transform(myDf['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PreProcessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointremove(image):\n",
    "    \n",
    "    img=image.copy()\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(img, connectivity=4)\n",
    "    sizes = stats[:, -1]\n",
    "    for i in range(1, nb_components):\n",
    "        if sizes[i]<100 :\n",
    "            img[output==i]=0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxmeanpreprop(path):\n",
    "    img1 = cv2.imread(path)\n",
    "    g_img = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img = g_img.copy()\n",
    "    ret1,th1 = cv2.threshold(g_img,40,255,cv2.THRESH_BINARY)\n",
    "    th1=pointremove(th1)\n",
    "    blur = cv2.GaussianBlur(th1,(5,5),0)\n",
    "    ret2,th2 = cv2.threshold(blur,130,255,cv2.THRESH_OTSU)\n",
    "\n",
    "    a_img=th2&img\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(a_img, connectivity=4)\n",
    "    sizes = stats[:, -1]\n",
    "\n",
    "    max_label = 0\n",
    "    max_mean = 0\n",
    "\n",
    "    for i in range(1, nb_components):\n",
    "        mean=np.mean(a_img[output==i])\n",
    "        if mean > max_mean and sizes[i]>1000 :\n",
    "            max_label = i\n",
    "            max_mean = mean\n",
    "\n",
    "    img3 = np.zeros(output.shape)\n",
    "    img3[output == max_label] = 255\n",
    "    new_image = img3[stats[max_label][1]:stats[max_label][1]+stats[max_label][3],stats[max_label][0]:stats[max_label][0]+stats[max_label][2]]\n",
    "    image_for_input = cv2.resize(new_image, (100, 100), interpolation = cv2.INTER_NEAREST)\n",
    "    return image_for_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_generator(features, batch_size=32):\n",
    "    # Create empty arrays to contain batch of features and labels#\n",
    "    batch_features = np.zeros((batch_size, 100, 100, 1))\n",
    "    batch_labels = np.zeros((batch_size))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # choose random index in features\n",
    "            index = np.random.choice(len(features),1)\n",
    "            batch_features[i] = maxmeanpreprop(features.loc[index[0]]['fileName']).reshape([100, 100, 1])\n",
    "            batch_labels[i] = features.loc[index[0]]['label_val']\n",
    "        yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=200, epochs=10)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 610s 3s/step - loss: 17.2736 - accuracy: 0.5919\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 611s 3s/step - loss: 0.8062 - accuracy: 0.7806\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 620s 3s/step - loss: 0.6391 - accuracy: 0.8306\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 822s 4s/step - loss: 0.5159 - accuracy: 0.8647\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 816s 4s/step - loss: 0.4633 - accuracy: 0.8853\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 589s 3s/step - loss: 0.4171 - accuracy: 0.8952\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 586s 3s/step - loss: 0.3593 - accuracy: 0.9072\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 3446s 17s/step - loss: 0.3166 - accuracy: 0.9159\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 607s 3s/step - loss: 0.3078 - accuracy: 0.9233\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 611s 3s/step - loss: 0.2990 - accuracy: 0.9244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20250ce6208>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(100, kernel_size=3, activation=\"relu\", input_shape=(100,100,1)))\n",
    "model.add(Conv2D(100, kernel_size=3, activation=\"relu\"))\n",
    "model.add(Conv2D(100, kernel_size=3, activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation=\"softmax\"))\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# # Fit the model\n",
    "model.fit_generator(my_generator(myDf), samples_per_epoch=200, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 384s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8004822323987881, 0.7819333076477051]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size=15000\n",
    "X=np.zeros((input_size,100,100,1))\n",
    "Y=np.zeros((input_size))\n",
    "X_file=[]\n",
    "Y_va=[]\n",
    "for fileName in sorted(glob.iglob('near-infrared/**/test_pose/**/**', recursive=False)):\n",
    "    X_file.append(fileName)\n",
    "    Y_va.append(fileName.split(\"\\\\\")[-2])\n",
    "Y1=myLabelEncoder.fit_transform(Y_va)    \n",
    "i=-1\n",
    "for i in range(len(X_file)):\n",
    "    i=i+1\n",
    "    if(i==input_size):\n",
    "        break\n",
    "    image=maxmeanpreprop(X_file[i]).reshape(100,100,1)\n",
    "    X[i]=image\n",
    "    Y[i]=Y1[i]\n",
    "model.evaluate(X,Y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
