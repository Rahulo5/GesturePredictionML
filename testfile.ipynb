{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import numpy\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fileName = []\n",
    "y_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileName in sorted(glob.iglob('near-infrared/**/train_pose/**/**', recursive=False)):\n",
    "    X_fileName.append(fileName)\n",
    "    y_val.append(fileName.split(\"\\\\\")[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDf = pd.DataFrame()\n",
    "myDf['fileName'] = X_fileName\n",
    "myDf['label'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "myLabelEncoder = LabelEncoder()\n",
    "myDf['label_val'] = myLabelEncoder.fit_transform(myDf['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PreProcessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointremove(image):\n",
    "    \n",
    "    img=image.copy()\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(img, connectivity=4)\n",
    "    sizes = stats[:, -1]\n",
    "    for i in range(1, nb_components):\n",
    "        if sizes[i]<100 :\n",
    "            img[output==i]=0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxmeanpreprop(path):\n",
    "    img1 = cv2.imread(path)\n",
    "    g_img = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img = g_img.copy()\n",
    "    ret1,th1 = cv2.threshold(g_img,40,255,cv2.THRESH_BINARY)\n",
    "    th1=pointremove(th1)\n",
    "    blur = cv2.GaussianBlur(th1,(5,5),0)\n",
    "    ret2,th2 = cv2.threshold(blur,130,255,cv2.THRESH_OTSU)\n",
    "\n",
    "    a_img=th2&img\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(a_img, connectivity=4)\n",
    "    sizes = stats[:, -1]\n",
    "\n",
    "    max_label = 0\n",
    "    max_mean = 0\n",
    "\n",
    "    for i in range(1, nb_components):\n",
    "        mean=np.mean(a_img[output==i])\n",
    "        if mean > max_mean and sizes[i]>1000 :\n",
    "            max_label = i\n",
    "            max_mean = mean\n",
    "\n",
    "    img3 = np.zeros(output.shape)\n",
    "    img3[output == max_label] = 255\n",
    "    new_image = img3[stats[max_label][1]:stats[max_label][1]+stats[max_label][3],stats[max_label][0]:stats[max_label][0]+stats[max_label][2]]\n",
    "    image_for_input = cv2.resize(new_image, (100, 100), interpolation = cv2.INTER_NEAREST)\n",
    "    return image_for_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating my generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_generator(features, batch_size=128):\n",
    "    # Create empty arrays to contain batch of features and labels#\n",
    "    batch_features = np.zeros((batch_size, 100, 100, 1))\n",
    "    batch_labels = np.zeros((batch_size))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # choose random index in features\n",
    "            index = np.random.choice(len(features),1)\n",
    "            batch_features[i] = maxmeanpreprop(features.loc[index[0]]['fileName']).reshape([100, 100, 1])\n",
    "            batch_labels[i] = features.loc[index[0]]['label_val']\n",
    "        yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MyModel(input_shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Lambda(lambda x: x / 255 - 0.5, input_shape=input_shape))\n",
    "\n",
    "    model.add(Conv2D(24, 5, 5, activation='relu', subsample=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(36, 5, 5, activation='relu', subsample=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(48, 5, 5, activation='relu', subsample=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(16, activation='softmax'))\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  import sys\n",
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n"
     ]
    }
   ],
   "source": [
    "myMod = MyModel([100, 100, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\akkir\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=100, epochs=40)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "100/100 [==============================] - 152s 2s/step - loss: 2.6363 - accuracy: 0.1620\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 151s 2s/step - loss: 2.1795 - accuracy: 0.3119\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 152s 2s/step - loss: 1.7147 - accuracy: 0.4389\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 148s 1s/step - loss: 1.4030 - accuracy: 0.5332\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 148s 1s/step - loss: 1.1831 - accuracy: 0.6061\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 147s 1s/step - loss: 1.0304 - accuracy: 0.6700\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 147s 1s/step - loss: 0.9132 - accuracy: 0.7028\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 147s 1s/step - loss: 0.8131 - accuracy: 0.7434\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 155s 2s/step - loss: 0.7277 - accuracy: 0.7741\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 154s 2s/step - loss: 0.6548 - accuracy: 0.7958\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 158s 2s/step - loss: 0.6336 - accuracy: 0.8075\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 155s 2s/step - loss: 0.5813 - accuracy: 0.8225\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 156s 2s/step - loss: 0.5602 - accuracy: 0.8312\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 157s 2s/step - loss: 0.5141 - accuracy: 0.8410\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 153s 2s/step - loss: 0.4958 - accuracy: 0.8492\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 150s 2s/step - loss: 0.4787 - accuracy: 0.8555\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 146s 1s/step - loss: 0.4594 - accuracy: 0.8638\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 151s 2s/step - loss: 0.4367 - accuracy: 0.8690\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 144s 1s/step - loss: 0.4101 - accuracy: 0.8786\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 144s 1s/step - loss: 0.4024 - accuracy: 0.8771\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 161s 2s/step - loss: 0.4141 - accuracy: 0.8770\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 167s 2s/step - loss: 0.4015 - accuracy: 0.8781\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 163s 2s/step - loss: 0.3742 - accuracy: 0.8881\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 159s 2s/step - loss: 0.3837 - accuracy: 0.8851\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 157s 2s/step - loss: 0.3530 - accuracy: 0.8916\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 154s 2s/step - loss: 0.3501 - accuracy: 0.8948\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 152s 2s/step - loss: 0.3512 - accuracy: 0.8940\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 155s 2s/step - loss: 0.3304 - accuracy: 0.9029\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 151s 2s/step - loss: 0.3165 - accuracy: 0.9044\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 150s 1s/step - loss: 0.3319 - accuracy: 0.9032\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 149s 1s/step - loss: 0.3155 - accuracy: 0.9086\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 149s 1s/step - loss: 0.3098 - accuracy: 0.9080\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 200s 2s/step - loss: 0.3171 - accuracy: 0.9048\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 167s 2s/step - loss: 0.3121 - accuracy: 0.9082\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 161s 2s/step - loss: 0.2999 - accuracy: 0.9090\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 158s 2s/step - loss: 0.2928 - accuracy: 0.9123\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 157s 2s/step - loss: 0.2769 - accuracy: 0.9175\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 156s 2s/step - loss: 0.2743 - accuracy: 0.9177\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 154s 2s/step - loss: 0.2832 - accuracy: 0.9157\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 156s 2s/step - loss: 0.2752 - accuracy: 0.9197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ab7f829c88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myMod.fit_generator(my_generator(myDf), samples_per_epoch=100, nb_epoch=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "def testing(input_size):\n",
    "    X=np.zeros((input_size,100,100,1))\n",
    "    Y=np.zeros((input_size))\n",
    "    X_file=[]\n",
    "    Y_va=[]\n",
    "    for fileName in sorted(glob.iglob('near-infrared/**/test_pose/**/**', recursive=False)):\n",
    "        X_file.append(fileName)\n",
    "        Y_va.append(fileName.split(\"\\\\\")[-2])\n",
    "    Y1=myLabelEncoder.transform(Y_va)    \n",
    "    k=-1\n",
    "    for i in range(len(X_file)):\n",
    "        k=k+1\n",
    "        if (k==input_size):\n",
    "            break\n",
    "        image=maxmeanpreprop(X_file[i]).reshape(100,100,1)\n",
    "        X[i]=image\n",
    "        Y[i]=Y1[i]\n",
    "        \n",
    "    prediction = myMod.predict(X)\n",
    "    print(prediction[3])\n",
    "    compare_x=[]\n",
    "    \n",
    "    for i in range(input_size):\n",
    "        result=np.where(prediction[i] == max(prediction[i]))\n",
    "        if result[0] !=None:\n",
    "            compare_x.append(result[0][0])\n",
    "        else :\n",
    "            compare_x.append(-1)        \n",
    "    accuracy = accuracy_score(Y,compare_x)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    f1 = f1_score(Y,compare_x,pos_label='positive',average='micro')\n",
    "    print('F1 score: %f' % f1)\n",
    "    print(\"Confusion Matrix :\")\n",
    "    print(confusion_matrix(compare_x,Y))\n",
    "    print(compare_x)\n",
    "    print(Y)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10944539 0.05764138 0.06685384 0.05657857 0.00677484 0.04318579\n",
      " 0.1726622  0.17781255 0.02331885 0.13217513 0.02231963 0.02620497\n",
      " 0.0059756  0.06674547 0.03114922 0.00115662]\n",
      "Accuracy: 0.922000\n",
      "F1 score: 0.922000\n",
      "Confusion Matrix :\n",
      "[[67  6  0  0  0  0  0  0  0  8  0  0  0  0  0  0]\n",
      " [ 1 69  0  0  0  0  0  0  0  0  0  0  0  0  3  0]\n",
      " [ 3  0 48  1  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 1  0  0 74  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 77  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2 74  0  0  0  0  0  0  0  4  0  0]\n",
      " [ 1  0  0  0  0  0 76  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0 75  1  0  0  0  0  1  0  0]\n",
      " [ 0  5  0  0  0  0  0  2 56  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0 32  0  0  0  0  0  0]\n",
      " [ 1  0  2  0  0  0  2  0  0  0 55  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  1  0  0  0  0  1 57  0  0  1  0]\n",
      " [ 3  0  0  0  1  0  0  1  1  0  0  1 56  0  1  0]\n",
      " [ 0  0  0  0  0  4  0  0  0  0  0  0  0 35  1  0]\n",
      " [ 0  0  0  0  0  0  1  2  4  0  0  0  0  0 34  0]\n",
      " [ 0  0  0  5  0  0  0  0  0  0  0  0  0  0  0 37]]\n",
      "[0, 0, 0, 7, 0, 0, 0, 2, 0, 0, 3, 2, 0, 6, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 12, 12, 12, 11, 0, 0, 1, 9, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 8, 1, 1, 8, 8, 8, 1, 0, 1, 1, 1, 1, 8, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 15, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 12, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 13, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 13, 5, 5, 5, 5, 5, 5, 4, 11, 5, 13, 5, 13, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 14, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 10, 6, 6, 6, 6, 6, 10, 6, 6, 6, 6, 6, 6, 3, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 12, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 14, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 14, 14, 8, 7, 8, 8, 8, 8, 8, 8, 8, 14, 8, 2, 8, 8, 14, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 12, 8, 8, 8, 9, 9, 0, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 0, 0, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 5, 5, 7, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 5, 13, 5, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 1, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 1, 14, 14, 13, 1, 12, 14, 14, 14, 14, 14, 14, 14, 14, 14, 11, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 10, 10, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 15, 15, 15, 3, 3, 15, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 14, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  3.\n",
      "  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "  3.  3.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      "  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      "  4.  4.  4.  4.  4.  4.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.\n",
      "  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.\n",
      "  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  6.  6.  6.  6.  6.  6.  6.  6.\n",
      "  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.\n",
      "  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  7.  7.  7.  7.\n",
      "  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.\n",
      "  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.\n",
      "  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.  9.\n",
      "  9.  9.  9.  9.  9.  9.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
      " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
      " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.\n",
      " 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 11. 11. 11. 11. 11. 11. 11. 11.\n",
      " 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11.\n",
      " 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11.\n",
      " 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 11. 12. 12. 12. 12.\n",
      " 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.\n",
      " 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12.\n",
      " 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 12. 13. 13.\n",
      " 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13.\n",
      " 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13. 13.\n",
      " 13. 13. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14.\n",
      " 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14. 14.\n",
      " 14. 14. 14. 14. 14. 14. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15.\n",
      " 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15. 15.\n",
      " 15. 15. 15. 15. 15. 15. 15.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "  3.  3.  3.  3.  3.  3.  3.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      "  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.\n",
      "  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  4.  5.  5.  5.  5.  5.  5.  5.\n",
      "  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.\n",
      "  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  6.  6.  6.\n",
      "  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.\n",
      "  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.\n",
      "  6.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.\n",
      "  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.  7.\n",
      "  7.  7.  7.  7.  7.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.]\n"
     ]
    }
   ],
   "source": [
    "testing(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
