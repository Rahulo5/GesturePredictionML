{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fileName = []\n",
    "y_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fileName in sorted(glob.iglob('near-infrared/**/train_pose/**/**', recursive=False)):\n",
    "    X_fileName.append(fileName)\n",
    "    y_val.append(fileName.split(\"\\\\\")[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting to DataFrame for easy handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDf = pd.DataFrame()\n",
    "myDf['fileName'] = X_fileName\n",
    "myDf['label'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "myLabelEncoder = LabelEncoder()\n",
    "myDf['label_val'] = myLabelEncoder.fit_transform(myDf['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingSingleImage(filepath):\n",
    "    \n",
    "    img = cv2.imread(filepath)\n",
    "    img1 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    k = cv2.normalize(img1, dst=None, alpha=0, beta=255,norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    blur = cv2.GaussianBlur(k,(5,5),0)\n",
    "    ret, thresh1 = cv2.threshold(blur, 60, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(thresh1, connectivity=4)\n",
    "    sizes = stats[:, -1]\n",
    "\n",
    "    max_label = 1\n",
    "    max_size = sizes[1]\n",
    "    \n",
    "    for k in range(2, nb_components):\n",
    "        if sizes[k] > max_size:\n",
    "            max_label = k\n",
    "            max_size = sizes[k]\n",
    "\n",
    "    img2 = np.zeros(output.shape)\n",
    "    img2[output == max_label] = 255\n",
    "\n",
    "    new_image = img2[stats[max_label][1]:stats[max_label][1]+stats[max_label][3],stats[max_label][0]:stats[max_label][0]+stats[max_label][2]]\n",
    "    image_for_input = cv2.resize(new_image, (100, 100), interpolation = cv2.INTER_NEAREST)\n",
    "    \n",
    "    return image_for_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1de95494c48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(preprocessingSingleImage(myDf['fileName'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating our generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_generator(features, batch_size=16):\n",
    "    # Create empty arrays to contain batch of features and labels#\n",
    "    batch_features = np.zeros((batch_size, 100, 100, 1))\n",
    "    batch_labels = np.zeros((batch_size))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # choose random index in features\n",
    "            index = np.random.choice(len(features),1)\n",
    "            batch_features[i] = preprocessingSingleImage(features.loc[index[0]]['fileName']).reshape([100, 100, 1])\n",
    "            batch_labels[i] = features.loc[index[0]]['label_val']\n",
    "        yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nvidia Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import necessary building blocks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel(input_shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Lambda(lambda x: x / 255 - 0.5, input_shape=input_shape))\n",
    "\n",
    "    model.add(Conv2D(24, 5, 5, activation='relu', subsample=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(36, 5, 5, activation='relu', subsample=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(48, 5, 5, activation='relu', subsample=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"relu\", strides=(2, 2))`\n",
      "  del sys.path[0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n"
     ]
    }
   ],
   "source": [
    "myMod = MyModel([100, 100, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=200, epochs=5)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 23.9552 - accuracy: 0.0622\n",
      "Epoch 2/5\n",
      "169/200 [========================>.....] - ETA: 4s - loss: 18.0242 - accuracy: 0.0721"
     ]
    }
   ],
   "source": [
    "myMod.fit_generator(my_generator(myDf), samples_per_epoch=200, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
